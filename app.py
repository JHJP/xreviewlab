import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
import matplotlib
matplotlib.use('Agg')
from flask import Flask, render_template, request, session, jsonify
import numpy as np
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Š  Brand-reputation research â†’ â‚© per DAMAGE-UNIT
# ----------------------------------------------------------------
# Why 12 500 â‚© ?  (sources â¬‡ï¸)
# â€¢ Harvard Business School (Luca 2016): every â˜… on Yelp shifts revenue
#   by â‰ˆ 5-9 %. 
# â€¢ Gominga â€œOnline Review Stats 2024â€: one bad review can scare away
#   ~30 shoppers & 40 % of prospects. 
# â€¢ Statistics Korea (2024): avg e-commerce basket â‰ˆ â‚©51 800.
#
# Worst-case loss for a *high-damage* review:
#     30 customers Ã— â‚©51 800  â‰ˆ â‚©1 554 000
# The same reviewâ€™s `compute_damage()` score peaks â‰ˆ 125 units
# (explicit warning + long text + aged).                âŸ¶  1 unit
#     1 554 000 / 125  â‰ˆ â‚©12 400  â†’ rounded â†’ **â‚©12 500**
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WON_PER_DAMAGE_UNIT: float = 12_500

app = Flask(__name__)
app.secret_key = 'replace_this_with_a_random_secret_1234'

# ì§„í–‰ìƒí™© ì´ˆê¸°í™”
def init_progress(total):
    session['progress_current'] = 0
    session['progress_total'] = total
    session.modified = True

def increment_progress():
    session['progress_current'] = session.get('progress_current', 0) + 1
    session.modified = True

def get_progress():
    return session.get('progress_current', 0), session.get('progress_total', 1)

@app.route('/progress')
def progress():
    current, total = get_progress()
    logging.info('[progress API] %s %s', current, total)  # ì„œë²„ ì½˜ì†”ì— ì§ì ‘ ì°ê¸°
    return jsonify({'current': current, 'total': total})

@app.route("/", methods=["GET", "POST"])
def index():
    # â”€â”€ 1. show welcome/tutorial overlay only the first time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if request.method == "POST":
        session["tutorial_seen"] = True 
    tutorial_mode = not session.get("tutorial_seen", False)

    # â”€â”€ 2. POST: ê¸°ì¡´ í¬ë¡¤ë§/ì €ì¥ ë¡œì§ ìœ ì§€ â”€â”€
    import time
    if request.method == "POST":
        t_post_start = time.time()
        brand_name = request.form.get("brand_name")
        brand_url = request.form.get("brand_url")
        products = []
        olive_products_df = None
        if brand_name:
            try:
                logging.info("[TIMER] í¬ë¡¤ëŸ¬ import ë° olive_get_brand_code ì‹œì‘")
                t_crawler_start = time.time()
                from crawlers.olive_crawler import olive_get_brand_code, olive_products_crawl
                brand_code = olive_get_brand_code(brand_name)
                logging.info(f"[TIMER] olive_get_brand_code ì™„ë£Œ: {time.time() - t_crawler_start:.2f}s")
                t_crawl_all_start = time.time()
                # ë¸Œëœë“œì˜ ëª¨ë“  ìƒí’ˆ ê°€ì ¸ì˜¤ê¸°
                all_products = []
                olive_products_df = olive_products_crawl(brand_code, limit=3)
                olive_products_df["platform"] = "olive"
                all_products.append(olive_products_df)
                if all_products:
                    import pandas as pd
                    total_products_df = pd.concat(all_products, ignore_index=True)
                logging.info(f"[TIMER] olive_products_crawl ì™„ë£Œ: {time.time() - t_crawl_all_start:.2f}s")
                t_loop_start = time.time()
                # ì „ì²´ ìƒí’ˆ ì •ë³´ ì €ì¥
                # ìƒí’ˆë³„ damage ì´í•© ê³„ì‚° (CSVê°€ ìˆìœ¼ë©´ í™œìš©)
                import os
                import pandas as pd
                csv_path = os.path.join(os.path.dirname(__file__), 'total_brand_reviews_df.csv')
                damage_sum_map = {}
                if os.path.exists(csv_path):
                    df = pd.read_csv(csv_path)
                    if 'prd_name' in df.columns and 'damage' in df.columns:
                        for prd_name, group in df.groupby('prd_name'):
                            damage_sum_map[prd_name] = group['damage'].sum()
                for _, row in total_products_df.iterrows():
                    damage_sum = damage_sum_map.get(row['name'], None)
                    products.append({
                        'goodsNo': row['goodsNo'],
                        'name': row['name'],
                        'rating': row['rating'],
                        'link': row['link'] if 'link' in row else '',
                        'platform': row['platform'],
                        'damage_sum': damage_sum
                    })
                logging.info(f"[TIMER] ìƒí’ˆ ë°˜ë³µë¬¸ ì™„ë£Œ: {time.time() - t_loop_start:.2f}s")
            except Exception as e:
                logging.error(f"[ERROR] ë¸Œëœë“œ ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        else:
            # ë¸Œëœë“œëª… ì—†ì´ ì „ì²´ ìƒí’ˆ fallback í¬ë¡¤ë§
            try:
                logging.info("[TIMER] fallback: olive_products_crawl(None) ì „ì²´ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘")
                from crawlers.olive_crawler import olive_products_crawl
                olive_products_df = olive_products_crawl(None, limit=10)
                olive_products_df["platform"] = "olive"
                total_products_df = olive_products_df
                logging.info(f"[TIMER] fallback: olive_products_crawl(None) ì™„ë£Œ")
                t_loop_start = time.time()
                products = []
                for _, row in total_products_df.iterrows():
                    products.append({
                        'goodsNo': row['goodsNo'],
                        'name': row['name'],
                        'rating': row['rating'],
                        'link': row['link'] if 'link' in row else '',
                        'platform': row['platform'],
                        'damage_sum': None
                    })
                logging.info(f"[TIMER] fallback ìƒí’ˆ ë°˜ë³µë¬¸ ì™„ë£Œ: {time.time() - t_loop_start:.2f}s")
            except Exception as e:
                logging.error(f"[ERROR] fallback ì „ì²´ìƒí’ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        session['total_products'] = products
        session['olive_products_df'] = olive_products_df.to_dict() if olive_products_df is not None else None
        # ---- ì „ì²´ ìƒí’ˆ ë¦¬ë·° ìˆ˜ì§‘ ë° í•©ì¹˜ê¸° ----
        import pandas as pd
        from crawlers.olive_crawler import olive_reviews_crawl
        from review_utils import extract_keywords_with_openai
        all_reviews = []
        for prod in products:
            goodsNo = prod['goodsNo']
            platform = prod.get('platform', '')
            try:
                if platform == 'olive':
                    reviews_df = olive_reviews_crawl([goodsNo], limit=5)
                    if reviews_df is not None and not reviews_df.empty:
                        reviews_df["word_count"] = reviews_df["content"].str.split().apply(len)
                        from routes.damage_calc import calculate_damage
                        reviews_df = calculate_damage(reviews_df)
                        reviews_df["keywords"] = reviews_df["content"].apply(extract_keywords_with_openai)
                        reviews_df["prd_link"] = prod.get('link', '')
                        reviews_df["prd_name"] = prod.get('name', '')
                        reviews_df["rating"] = prod.get('rating', '')
                        reviews_df["prd_platform"] = platform
                        all_reviews.append(reviews_df)
            except Exception as e:
                logging.error(f"[ERROR] ë¦¬ë·° ìˆ˜ì§‘ ì‹¤íŒ¨: goodsNo={goodsNo}, error={e}")
        if all_reviews:
            total_brand_reviews_df = pd.concat(all_reviews, ignore_index=True)
            total_brand_reviews_df.to_csv('total_brand_reviews_df.csv', index=False, encoding='utf-8-sig')
            logging.info(f"[INFO] total_brand_reviews_df.csv ì €ì¥ ì™„ë£Œ: {len(total_brand_reviews_df)}ê±´")
            # --- í‚¤ì›Œë“œ í´ëŸ¬ìŠ¤í„°ë§ ë° damage ì§‘ê³„ ì‹¤í–‰ ---
            from keyword_clustering_and_damage import run_keyword_clustering_and_damage
            run_keyword_clustering_and_damage('total_brand_reviews_df.csv')
        else:
            logging.info("[INFO] ìˆ˜ì§‘ëœ ë¦¬ë·° ì—†ìŒ. total_brand_reviews_df.csv ë¯¸ìƒì„±")
        logging.info(f"[TIMER] ì „ì²´ POST ì²˜ë¦¬ ì™„ë£Œ: {time.time() - t_post_start:.2f}s")
        return render_template(
            "index.html",
            products=products,
            tutorial_mode=tutorial_mode
        )

    # â”€â”€ 3. GET: CSVì—ì„œ ìƒí’ˆë³„ í…Œì´ë¸” ì§ì ‘ ì§‘ê³„ â”€â”€
    import os
    import pandas as pd
    csv_path = os.path.join(os.path.dirname(__file__), 'total_brand_reviews_df.csv')
    products = []
    if os.path.exists(csv_path):
        df = pd.read_csv(csv_path)
        grouped = df.groupby('prd_name').agg({
            'rating': 'mean',
            'damage': 'sum',
            'goodsNo': 'first',
            'prd_link': 'first',
            'real_keywords_all': 'first'
        }).reset_index()
        from review_utils import get_top5_keywords_from_list
        import ast
        for _, row in grouped.iterrows():
            real_keywords_all = []
            val = row.get('real_keywords_all', None)
            if pd.notnull(val):
                if isinstance(val, str):
                    try:
                        real_keywords_all = ast.literal_eval(val)
                    except Exception:
                        real_keywords_all = []
                elif isinstance(val, list):
                    real_keywords_all = val
            top5_keywords = get_top5_keywords_from_list(real_keywords_all)
            products.append({
                'goodsNo': row['goodsNo'],
                'name': row['prd_name'],
                'rating': round(row['rating'], 2) if pd.notnull(row['rating']) else '',
                'damage_sum': round(row['damage'], 2) if pd.notnull(row['damage']) else 0,
                'link': row['prd_link'],
                'top5_keywords': top5_keywords
            })
    return render_template(
        "index.html",
        products=products,
        tutorial_mode=tutorial_mode
    )

# VoC ë“£ê¸°: ê°•ì œ ìƒˆë¡œê³ ì¹¨ìš© ë¼ìš°íŠ¸ (í”„ë¡ íŠ¸ì—ì„œ ë²„íŠ¼ìœ¼ë¡œ í˜¸ì¶œ)
@app.route("/voc_listen", methods=["POST"])
def voc_listen():
    from flask import request
    brand_name = request.form.get("brand_name")
    brand_url = request.form.get("brand_url")
    # Run the main index logic (crawling, saving, etc)
    with app.test_request_context('/', method='POST', data={'brand_name': brand_name or '', 'brand_url': brand_url or ''}):
        response = index()
    # After crawling, run embedding computation
    from embed_reviews import compute_review_embeddings
    try:
        compute_review_embeddings()
    except Exception as e:
        import logging
        logging.error(f"[ì„ë² ë”© ì˜¤ë¥˜] {e}")
    return response


# Blueprint ë“±ë¡
from routes.auto_reply import auto_reply_bp
from routes.product import product_bp
app.register_blueprint(auto_reply_bp)
app.register_blueprint(product_bp)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True, use_reloader=False)
