from flask import Flask, render_template, request, session, send_file, redirect, url_for, jsonify
import pandas as pd
from optimizer_gurobi import optimize, METHODS, compute_damage
import numpy as np
# ì¶”ê°€: ì›Œë“œí´ë¼ìš°ë“œ ê´€ë ¨
from collections import Counter
import io, base64
from wordcloud import WordCloud
from konlpy.tag import Okt
import matplotlib.pyplot as plt
import os
from dotenv import load_dotenv
import openai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Š  Brand-reputation research â†’ â‚© per DAMAGE-UNIT
# ----------------------------------------------------------------
# Why 12 500 â‚© ?  (sources â¬‡ï¸)
# â€¢ Harvard Business School (Luca 2016): every â˜… on Yelp shifts revenue
#   by â‰ˆ 5-9 %. 
# â€¢ Gominga â€œOnline Review Stats 2024â€: one bad review can scare away
#   ~30 shoppers & 40 % of prospects. 
# â€¢ Statistics Korea (2024): avg e-commerce basket â‰ˆ â‚©51 800.
#
# Worst-case loss for a *high-damage* review:
#     30 customers Ã— â‚©51 800  â‰ˆ â‚©1 554 000
# The same reviewâ€™s `compute_damage()` score peaks â‰ˆ 125 units
# (explicit warning + long text + aged).                âŸ¶  1 unit
#     1 554 000 / 125  â‰ˆ â‚©12 400  â†’ rounded â†’ **â‚©12 500**
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WON_PER_DAMAGE_UNIT: float = 12_500

def risk_bucket(score: float, low_thresh: float, high_thresh: float):
    """
    Return (slug, korean_label)  e.g.  ( "medium", "ë³´í†µ" )
    * low_thresh  : at-or-below this   â†’ low   (ë‚®ìŒ)
    * high_thresh : at-or-below this   â†’ medium(ë³´í†µ)
    * above high_thresh               â†’ high  (ë†’ìŒ)
    """
    if score <= low_thresh:
        return ("low",    "ë‚®ìŒ")
    elif score <= high_thresh:
        return ("medium", "ë³´í†µ")
    else:
        return ("high",   "ë†’ìŒ")

app = Flask(__name__)
app.secret_key = 'replace_this_with_a_random_secret_1234'

# ì§„í–‰ìƒí™© ì´ˆê¸°í™”
def init_progress(total):
    session['progress_current'] = 0
    session['progress_total'] = total
    session.modified = True

def increment_progress():
    session['progress_current'] = session.get('progress_current', 0) + 1
    session.modified = True

def get_progress():
    return session.get('progress_current', 0), session.get('progress_total', 1)

@app.route('/progress')
def progress():
    current, total = get_progress()
    print('[progress API]', current, total)  # ì„œë²„ ì½˜ì†”ì— ì§ì ‘ ì°ê¸°
    return jsonify({'current': current, 'total': total})

@app.route("/", methods=["GET", "POST"])
def index():
    # â”€â”€ 1. show welcome/tutorial overlay only the first time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if request.method == "POST":
        session["tutorial_seen"] = True 
    tutorial_mode = not session.get("tutorial_seen", False)

    # â”€â”€ 2. skeletons for the template (stay None on plain GET)
    recs = metrics = insights = None
    wordcloud_url = None

    # â”€â”€ 3. Handle the POST: run the optimiser & build the dashboard
    if request.method == "POST":

        # â”€â”€ 3-a. grab inputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        budget          = float(request.form["budget"])
        hours_available = float(request.form["total_hours_available"])

        # ë¸Œëœë“œ ì´ë¦„ ë°›ì•„ì„œ ì½”ë“œ ì¶”ì¶œ
        brand_name = request.form.get("brand_name")
        brand_code = None
        if brand_name:
            try:
                from crawlers.olive_crawler import get_brand_code, crawl_brand_all, crawl_reviews_for_goods
                brand_code = get_brand_code(brand_name)
                total_products_df = crawl_brand_all(brand_code, limit=3)
                goods_nos = total_products_df['goodsNo'].tolist()
                total_reviews_df = crawl_reviews_for_goods(goods_nos, limit=5)
            except Exception as e:
                print(f"[ERROR] ì˜¬ë¦¬ë¸Œì˜ ë¸Œëœë“œì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            prodlist_df = crawl_brand_all(brand_code)
        else:
            df              = pd.read_csv("reviews_sample_15.csv")

        # optional â€œallowed methodsâ€; default = all five
        allowed = request.form.getlist("methods") or METHODS

        # â”€â”€ 3-b. optimise & build dashboard numbers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rec_df, sens = optimize(
            df,
            budget,
            hours_available,
            allowed_methods=allowed
        )
        init_progress(len(df))  # ì „ì²´ ë¦¬ë·° ê°œìˆ˜ë¡œ ì´ˆê¸°í™” (POSTì—ì„œë§Œ!)

        # â”€â”€ 3-c. add risk buckets for UI chips â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # percentiles â‰ˆ terciles â†’ dynamic to the current batch
        p33, p66 = np.percentile(rec_df.risk_score, [33, 66])
        rec_df[["risk_slug", "risk_label"]] = rec_df.risk_score.apply(
            lambda s: pd.Series(risk_bucket(s, p33, p66))
        )
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 3-c.  What-if insight cards (from LP sensitivity)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Shadow prices:  ( â‰¤ constraints â‡’ Pi â‰¤ 0 in a minimisation model )
        shadow = sens.get("shadow_prices") or {}
        rhs    = shadow.get("rhs_ranges", {})
        sp     = shadow.get("shadow_prices", {})
        budget_slack = sens.get("budget_slack", None)
        time_slack = sens.get("time_slack", None)
        save_per_1k_budget = float(sp.get("budget", 0)) * 1000
        save_per_hour = float(sp.get("time", 0))
        budget_note = None
        time_note = None
        if save_per_1k_budget == 0 and budget_slack is not None and budget_slack > 0:
            budget_note = "ì˜ˆì‚° ì œì•½ì´ ëŠìŠ¨(slack)í•´ì ¸ í•œê³„íš¨ê³¼(Shadow price)ê°€ 0ì…ë‹ˆë‹¤. ì˜ˆì‚°ì„ ì¤„ì´ê±°ë‚˜ Î± ë¶ˆí™•ì‹¤ì„±ì„ ë‚®ì¶”ë©´ ê°’ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        if save_per_hour == 0 and time_slack is not None and time_slack > 0:
            time_note = "ì‹œê°„ ì œì•½ì´ ëŠìŠ¨(slack)í•´ì ¸ í•œê³„íš¨ê³¼(Shadow price)ê°€ 0ì…ë‹ˆë‹¤. ì‹œê°„ì„ ì¤„ì´ê±°ë‚˜ Î± ë¶ˆí™•ì‹¤ì„±ì„ ë‚®ì¶”ë©´ ê°’ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        insights = {
            "save_per_1k_budget": save_per_1k_budget,
            "save_per_hour":     save_per_hour,
            "budget_headroom":   float(rhs.get("budget", (None, None))[1] or 0) - float(budget),
            "hour_headroom":     float(rhs.get("time", (None, None))[1] or 0) - float(hours_available),
            "budget_note": budget_note,
            "time_note": time_note,
        }
        # Convert to customer-friendly â€œadditional damage PREVENTEDâ€
        whatif = dict(
            save_per_1k_budget = max(0.0, -float(sp.get("budget", 0)) * WON_PER_DAMAGE_UNIT * 1_000),   # â‚© saved / â‚©1 000
            save_per_hour      = max(0.0, -float(sp.get("time", 0)) * WON_PER_DAMAGE_UNIT),             # â‚© saved / hour
            # Optional head-room: how much budget could still yield that return
            budget_headroom = max(0.0,
                float(rhs.get("budget", (None, None))[1] or 0) - float(budget)
                if "rhs_ranges" in sens and "budget" in sens["rhs_ranges"] and isinstance(sens["rhs_ranges"]["budget"], (list, tuple)) and len(sens["rhs_ranges"]["budget"]) > 1 else 0.0
            ),
            hour_headroom = max(0.0,
                sens["rhs_ranges"]["time"][1] - hours_available
                if "rhs_ranges" in sens and "time" in sens["rhs_ranges"] and isinstance(sens["rhs_ranges"]["time"], (list, tuple)) and len(sens["rhs_ranges"]["time"]) > 1 else 0.0
            ),
        )
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ğŸ¯  HARD-ROI METRICS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1.   ì˜ˆâ€†ìƒâ€†ì†â€†í•´â€†ë°©â€†ì§€â€†ê¸ˆâ€†ì•¡  =  {(ì´ damage) â€“ (MILP ëª©ì í•¨ìˆ˜)}*WON_PER_DAMAGE_UNIT
        damage_before = compute_damage(df).sum()
        damage_after  = sens.get("obj_worst_case")  # solver objective
        if damage_after is None:
            # Fallback: show error message to user and skip calculation
            return render_template(
                "index.html",
                tutorial_mode=tutorial_mode,
                methods=METHODS,
                recommended_responses=None,
                metrics=None,
                insights=None,
                error_msg="ìµœì í™” ê²°ê³¼ì—ì„œ ëª©ì í•¨ìˆ˜ ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ê°’ì„ í™•ì¸í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            )
        net_damage_units = damage_before - damage_after          # â–²units
        net_damage_prevented = net_damage_units * WON_PER_DAMAGE_UNIT

        # 2.   ì˜ˆâ€†ìƒâ€†ë³„â€†ì â€†ìƒâ€†ìŠ¹â€†ëŸ‰
        if "review_stars" in df.columns:
            old_avg = df.review_stars.mean()

            # optimistic assumption: ëŒ€ì‘ë˜ë©´ ìµœì†Œ â˜…4ë¡œ íšŒë³µ
            new_stars = df.review_stars.copy()
            treated_ids = set(rec_df.review_id)
            low_mask = (df.index.isin(treated_ids)) & (df.review_stars < 4)
            new_stars.loc[low_mask] = 4

            avg_star_delta = float(new_stars.mean() - old_avg)
        else:
            avg_star_delta = 0.0

        # 3.   ì˜ˆâ€†ìƒâ€†ì‘â€†ë‹µâ€†ì‹œâ€†ê°„â€†ì ˆâ€†ê°â€†ëŸ‰
        TIME_PER_METHOD = {        # hours per review after automation
            "text_reply":      0.0833,   # 5 min (5/60)
            "chat_followup":   0.1667,   # 10 min (10/60)
            "phone_call":      0.5000,   # 30 min
            "discount_coupon": 0.0833,
            "vip_apology":     0.2500,
        }
        baseline_manual_time = 0.75          # 45â€†min(45min per review)
        baseline_total_hours = len(df) * baseline_manual_time

        optimised_total_hours = sum(
            TIME_PER_METHOD.get(row.method, 0.0) for row in rec_df.itertuples()
        )
        response_time_saved = baseline_total_hours - optimised_total_hours

        # 4.   ë¸Œâ€†ëœâ€†ë“œâ€†í‰â€†íŒâ€†íšŒâ€†ë³µâ€†ë¥   (= ë‚®ì€ ë³„ì  ì¤‘ ëª‡ %ë¥¼ êµ¬í•´ëƒˆë‚˜)
        if "review_stars" in df.columns:
            negative_mask = df.review_stars < 4
            total_neg = int(negative_mask.sum())
            recovered = int(
                df.loc[negative_mask & df.index.isin(treated_ids)].shape[0]
            )
            review_recovery_rate = recovered / total_neg if total_neg else 0.0
        else:
            review_recovery_rate = 0.0

        metrics = dict(
            net_damage_prevented = net_damage_prevented,
            avg_star_delta       = avg_star_delta,
            response_time_saved  = response_time_saved,
            review_recovery_rate = review_recovery_rate,
        )


        # ê° ë¦¬ë·°ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œê¸€/ì˜ì–´ ìë™ ì§€ì›)
        import re
        def extract_keywords(text):
            text = str(text)
            # í•œê¸€ í¬í•¨ ì—¬ë¶€
            if re.search(r"[\uac00-\ud7a3]", text):
                # í•œê¸€ ë¦¬ë·°: konlpy ì‚¬ìš©
                okt = Okt()
                return [w for w in okt.nouns(text) if len(w) > 1]
            else:
                # ì˜ì–´ ë¦¬ë·°: nltk ì‚¬ìš©, punkt_tab ì˜¤ë¥˜ ëŒ€ì‘
                import nltk
                try:
                    nltk.data.find('tokenizers/punkt')
                except LookupError:
                    nltk.download('punkt')
                try:
                    nltk.data.find('corpora/stopwords')
                except LookupError:
                    nltk.download('stopwords')
                try:
                    from nltk.corpus import stopwords
                    from nltk.tokenize import word_tokenize
                    words = word_tokenize(text)
                except LookupError:
                    try:
                        nltk.download('punkt_tab')
                        from nltk.tokenize import word_tokenize
                        words = word_tokenize(text)
                    except Exception:
                        # ë§ˆì§€ë§‰ fallback: ê³µë°± ê¸°ì¤€ ë¶„ë¦¬
                        words = text.split()
                stop_words = set(nltk.corpus.stopwords.words('english'))
                return [w.lower() for w in words if w.isalpha() and w.lower() not in stop_words and len(w) > 2]

        def extract_insight_keywords(review_text):
            import os, json
            from openai import OpenAI
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return extract_keywords(review_text)

            client = OpenAI(api_key=api_key)

            few_shot_messages = [
                {"role": "user",
                "content": "ë¦¬ë·°: ì§ì›ì´ ì¹œì ˆí–ˆì§€ë§Œ ìŒì‹ì´ ë„ˆë¬´ ëŠ¦ê²Œ ë‚˜ì™”ì–´ìš”."},
                {"role": "assistant",
                "content": '{"keywords":["ì§ì› ì¹œì ˆ","ìŒì‹ ì§€ì—°"]}'},
                {"role": "user",
                "content": "ë¦¬ë·°: ê°€ê²©ì´ ë¹„ì‹¸ê³  í’ˆì§ˆì´ ê¸°ëŒ€ ì´í•˜ì—¬ì„œ ì‹¤ë§í–ˆìŠµë‹ˆë‹¤."},
                {"role": "assistant",
                "content": '{"keywords":["ê°€ê²©","í’ˆì§ˆ"]}'},
            ]

            # 1) í‚¤ì›Œë“œ ì¶”ì¶œ ---------------------------------------------------------
            system_keyword = (
                "ë„ˆëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì„ ë•ëŠ” ë¶„ì„ê°€ë‹¤. "
                "ì•„ë˜ ë¦¬ë·°ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 3~6ê°œë¥¼ ì¶”ì¶œí•œë‹¤. "
                "ê° í‚¤ì›Œë“œëŠ” í•œêµ­ì–´ ëª…ì‚¬êµ¬ì—¬ì•¼ í•œë‹¤. "
                "ì¶œë ¥ì€ ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë°˜ë“œì‹œ ë”°ë¥¸ë‹¤.\n\n"
                '{\n  "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...]\n}\n'
                "ë‹¤ë¥¸ í…ìŠ¤íŠ¸(ì ‘ë‘ì–´Â·ì£¼ì„Â·ë§ˆì¹¨í‘œ ë“±)ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆë¼."
            )
            user_keyword = f"ë¦¬ë·°: {review_text}"

            messages= (
                    [{"role": "system", "content": system_keyword}]
                    + few_shot_messages
                    + [{"role": "user", "content": user_keyword}]
                )
            
            try:
                resp = client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    response_format={"type": "json_object"},
                    temperature=0.0,
                    max_tokens=128,
                )

                data = json.loads(resp.choices[0].message.content)
                keywords = data.get("keywords", [])
                if not isinstance(keywords, list):
                    raise ValueError("`keywords` í•„ë“œ í˜•ì‹ ì˜¤ë¥˜")
                return keywords

            except Exception:  # íŒŒì‹± ì‹¤íŒ¨ Â· API ì˜¤ë¥˜ ë“±
                return extract_keywords(review_text)




        def gpt_classify_and_reply(review_text):
            import os, json
            from openai import OpenAI
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return ("ë¶„ë¥˜ë¶ˆê°€", "AI ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API KEY ì—†ìŒ/ì˜¤ë¥˜)")

            client = OpenAI(api_key=api_key)

            # 1) ë¶„ë¥˜ -----------------------------------------------------------------
            system_cat = (
                "ë„ˆëŠ” ê³ ê° ë¦¬ë·°ë¥¼ ë‹¨ì¼ ë¶ˆë§Œ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” AI ëª¨ë¸ì´ë‹¤. "
                "ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì§€ì¼œì„œ í•œêµ­ì–´ë¡œ ì¶œë ¥í•´ë¼.\n\n"
                "ìŠ¤í‚¤ë§ˆ:\n"
                "{\n  \"category\": \"í’ˆì§ˆ | ê°€ê²© | ì„œë¹„ìŠ¤ | ê¸°íƒ€\"\n}\n"
                "â€» ê°€ëŠ¥í•œ ê°’ì€ ë”± ë„¤ ê°€ì§€ ì¤‘ í•˜ë‚˜ë‹¤. ê·¸ ì™¸ ë‹¨ì–´Â·ë§ˆì¹¨í‘œÂ·ê³µë°±ì„ ë„£ì§€ ë§ˆë¼."
            )
            user_cat = f"ë¦¬ë·°: {review_text}"

            cat_resp = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_cat},
                    {"role": "user", "content": user_cat}
                ],
                response_format={"type": "json_object"},  # JSON mode
                temperature=0.0,
                max_tokens=16,
            )

            try:
                category = json.loads(cat_resp.choices[0].message.content)["category"]
            except Exception:
                category = "ë¶„ë¥˜ì‹¤íŒ¨"

            # 2) ë‹µë³€ -----------------------------------------------------------------
            system_reply = (
                "ë„ˆëŠ” ê³ ê°ì‘ëŒ€ ì§ì›(agent)ì´ë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ì§€ì¼œ 2~4ë¬¸ì¥ í•œêµ­ì–´ë¡œ ë‹µí•˜ë¼.\n"
                "â‘  ì§„ì‹¬ ì–´ë¦° ì‚¬ê³¼ë¥¼ 1ë¬¸ì¥ í¬í•¨í•œë‹¤.\n"
                "â‘¡ ì‹¤ì œ ê°€ëŠ¥í•œ ë‚´ë¶€ ì¡°ì¹˜(ì›ì¸ ì ê²€, ì¬ë°œ ë°©ì§€ êµìœ¡ ë“±)ë§Œ ì œì‹œí•œë‹¤.\n"
                "â‘¢ ê¸ˆì „Â·ì¿ í°Â·ì‚¬ì€í’ˆÂ·ë¬´ë£Œ í˜œíƒ ì•½ì†ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ì•ŠëŠ”ë‹¤.\n"
                "â‘£ ì„œë¹„ìŠ¤ íšŒë³µ íŒ¨ëŸ¬ë…ìŠ¤(ì‚¬í›„ ëŒ€ì²˜ê°€ ë§Œì¡±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤ëŠ” ê°œë…)ë¥¼ ì—¼ë‘ì— ë‘ë˜, í˜„í•™ì  ìš©ì–´ëŠ” ì“°ì§€ ë§ˆë¼.\n"
                "â‘¤ íšŒì‚¬Â·ë¸Œëœë“œëª…ì€ ë„£ì§€ ì•ŠëŠ”ë‹¤."
            )
            user_reply = f"ë¦¬ë·°: {review_text}"

            reply_resp = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_reply},
                    {"role": "user", "content": user_reply}
                ],
                temperature=0.6,
                max_tokens=256,
            )

            suggested_reply = reply_resp.choices[0].message.content.strip()
            return (category, suggested_reply)

        recs = []
        for idx, row in enumerate(df.to_dict('records')):
            rec_row = next((r for r in rec_df.to_dict('records') if int(r['review_id']) == int(row.get('review_id', idx))), None)
            if rec_row is not None:
                kws = extract_insight_keywords(rec_row['review_text'])
                category, suggested_reply = gpt_classify_and_reply(rec_row['review_text'])
                # ë‚ ì§œëŠ” ë°˜ë“œì‹œ ì›ë³¸ df ê¸°ì¤€
                review_date = row.get('date') or row.get('ë‚ ì§œ') or row.get('DATE') or ''
                # ë‹µë³€ ì‹¤íŒ¨ ì•ˆë‚´ ë©”ì‹œì§€ ì²˜ë¦¬
                if suggested_reply.strip() in ["(ë‹µë³€ì‹¤íŒ¨)", "", None]:
                    print(f"[GPT ë‹µë³€ì‹¤íŒ¨] idx={idx}, review_id={rec_row.get('review_id')}, text={rec_row['review_text']}")
                    suggested_reply = "AI ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
                rec = {
                    'id': idx,
                    'review_id': rec_row['review_id'],
                    'method': rec_row['method'],
                    'risk_score_norm': rec_row['risk_score_norm'],
                    'review_text': rec_row['review_text'],
                    'keywords': kws,
                    'category': category,
                    'suggested_reply': suggested_reply,
                    'date': review_date
                }
                recs.append(rec)
                increment_progress()  # GPT ì‘ë‹µ ì‹œì—ë§Œ ì¹´ìš´íŠ¸ ì¦ê°€
        # ë°˜ë“œì‹œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¡œ ì„¸ì…˜ ë³´ì¡´ (ì¶”ì²œì¡°ì¹˜ ê²°ê³¼ë„ ì„¸ì…˜ì— ì €ì¥)
        session['recs'] = recs
        session.modified = True
        # index í•¨ìˆ˜ ì •ìƒ ì¢…ë£Œ: render_template ë“±ìœ¼ë¡œ ë°˜í™˜

    return render_template(
        "index.html",
        tutorial_mode          = tutorial_mode,
        methods                = METHODS,
        recommended_responses  = recs,
        metrics                = metrics,
        insights               = insights,
        wordcloud_url          = wordcloud_url
    )





import tempfile
from io import BytesIO
from PIL import Image
import base64
import pandas as pd
from openpyxl import Workbook
from openpyxl.drawing.image import Image as XLImage

@app.route("/download_report", methods=["GET"])
def download_report():
    report_data = session.get('report_data')
    if not report_data:
        return redirect(url_for('index'))
    recs = report_data['recs']
    metrics = report_data['metrics']
    insights = report_data['insights']
    wordcloud_url = report_data['wordcloud_url']
    # 1. ì¶”ì²œì¡°ì¹˜ í…Œì´ë¸” DataFrame ìƒì„±
    df = pd.DataFrame(recs)
    # 2. ì—‘ì…€ ìƒì„±
    wb = Workbook()
    ws = wb.active
    ws.title = "ì¶”ì²œì¡°ì¹˜"
    # í—¤ë”
    ws.append(list(df.columns))
    # ë°ì´í„°
    for row in df.itertuples(index=False):
        ws.append(list(row))
    # 3. ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ì‚½ì… (ìˆì„ ë•Œë§Œ)
    if wordcloud_url and wordcloud_url.startswith('data:image'):
        img_data = base64.b64decode(wordcloud_url.split(',')[1])
        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_img:
            tmp_img.write(img_data)
            tmp_img.flush()
            img = XLImage(tmp_img.name)
            img.width = 400
            img.height = 180
            ws.add_image(img, 'H2')
    # 4. metrics, insights ì‹œíŠ¸ ì¶”ê°€
    if metrics:
        ws2 = wb.create_sheet("íš¨ê³¼ìš”ì•½")
        for k, v in metrics.items():
            ws2.append([k, v])
    if insights:
        ws3 = wb.create_sheet("ì¸ì‚¬ì´íŠ¸")
        for k, v in insights.items():
            ws3.append([k, v])
    # 5. íŒŒì¼ë¡œ ì €ì¥ í›„ ë‹¤ìš´ë¡œë“œ
    with BytesIO() as output:
        wb.save(output)
        output.seek(0)
        return send_file(output, as_attachment=True, download_name="review_report.xlsx", mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

import smtplib
from email.message import EmailMessage

@app.route("/send_report_email", methods=["POST"])
def send_report_email():
    report_data = session.get('report_data')
    if not report_data:
        return redirect(url_for('index'))
    recs = report_data['recs']
    metrics = report_data['metrics']
    insights = report_data['insights']
    wordcloud_url = report_data['wordcloud_url']
    # 1. ì—‘ì…€ ë¦¬í¬íŠ¸ ìƒì„± (ë©”ëª¨ë¦¬)
    df = pd.DataFrame(recs)
    wb = Workbook()
    ws = wb.active
    ws.title = "ì¶”ì²œì¡°ì¹˜"
    ws.append(list(df.columns))
    for row in df.itertuples(index=False):
        ws.append(list(row))
    if wordcloud_url and wordcloud_url.startswith('data:image'):
        img_data = base64.b64decode(wordcloud_url.split(',')[1])
        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_img:
            tmp_img.write(img_data)
            tmp_img.flush()
            img = XLImage(tmp_img.name)
            img.width = 400
            img.height = 180
            ws.add_image(img, 'H2')
    if metrics:
        ws2 = wb.create_sheet("íš¨ê³¼ìš”ì•½")
        for k, v in metrics.items():
            ws2.append([k, v])
    if insights:
        ws3 = wb.create_sheet("ì¸ì‚¬ì´íŠ¸")
        for k, v in insights.items():
            ws3.append([k, v])
    with BytesIO() as output:
        wb.save(output)
        output.seek(0)
        xlsx_bytes = output.read()
    # 2. ì´ë©”ì¼ ë°œì†¡
    email_to = request.form.get('email')
    email_user = os.getenv('EMAIL_USER')
    email_password = os.getenv('EMAIL_PASSWORD')
    if not (email_to and email_user and email_password):
        return "ì´ë©”ì¼ ë°œì†¡ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.", 400
    msg = EmailMessage()
    msg['Subject'] = "ë¦¬ë·° ëŒ€ì‘ ë¦¬í¬íŠ¸"
    msg['From'] = email_user
    msg['To'] = email_to
    msg.set_content("ì²¨ë¶€íŒŒì¼ë¡œ ë¦¬ë·° ëŒ€ì‘ ë¦¬í¬íŠ¸ë¥¼ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.")
    msg.add_attachment(xlsx_bytes, maintype='application', subtype='vnd.openxmlformats-officedocument.spreadsheetml.sheet', filename='review_report.xlsx')
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:
            smtp.login(email_user, email_password)
            smtp.send_message(msg)
        return "ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤!", 200
    except Exception as e:
        return f"ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}", 500


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
